#
## Modele drzew decyzyjnych
Graficzny sposób podejmowania decyzji klasyfikacyjnych przypominających drzewo.

## W takim drzewie:
- Wierzchołek drzewa - wierzchołek zawierający wszystkie rekordy danych (pełny zbiór) - dane o postaci par (X, d)
- Węzeł decyzyjny - punkt sieci, w którym następuje podział zbioru na mniejsze dwa podzbiory
- Próg podziału zbioru wg określonej zmiennej/ych
- Liście - końcowe węzły podziału w których (docelowo) elementy należą do tylko jednej tej samej klasy

## Współczynnik zanieczyszczenia klasowego:
- Współczynnik giniego $I(A) = 1 - \displaystyle\sum_k r_k^2$, gdzie $r_k = \frac{\text{liczba reprezentantow klasy k}}{\text{liczba wszystkich reprezentantow klas}}$
    - Miara całkowita indeksu po podziale
    $$ I \left( \sum_k A_k \right) = \sum_k I(A_k) \cdot \frac{|A_k|}{|A|} $$
- Współczynnik entropii $E(A) = \displaystyle-\sum_k^\mu r_k \log_2r_k$

## Algorytm tworzenia drzew decyzyjnych
1. Dane wejściowe zgromadzone w macierzy X sklejamy z klasą d
2. Macierz $X \rightarrow X'$, gdzie macierz $X'$ ma każdą kolumnę posortowaną malejąco, a następnie pomiędzy dwoma sąsiadami wierzszy dopisujemy dodatkowy wiersz, który dla każdej kolumny ma wartość średnią wartości ponad i pod sobą. Te wartości to potencjalne progi 
3. Próbujemy dokonać podziału takiego zbioru według kolejnych zmiennych $x_i$ próbując wszystkie możliwe potencjalne progi dla tych zmiennych
4. Dla każdej możliwej kombinacji $(x_k, \text{potencjalny próg})$ określa się wypadkową (całkowitą) miarę zanieczyszczenia klasowego
5. Wybiera się to drzewo, które zawiera najmniejszą wartość miary
6. Repeat[2 - 5] aż do uzyskania liści drzewa (zerowych miar zanieczyszczenia)

## Ocena drzewa 
- Rozmiar drzewa - liczba węzłów, liczba liści, wysokość itd.
- Dokładność na zbiorze treningowym/uczącym 
- Dokładność na zbiorze testującym

## Regularyzacja drzewa
- By zapobiec przeuczeniu na zbiorze treningowym przycina się drzewo aka
- Obcinanie pewnych elementów/węzłów drzewa w celu ograniczenia wielkości drzewa decyzyjnego 

## Zalety i Wady
### Zalety
- Przejrzystość podejmowania decyzji
- Pełna odporność na braki danych
- Pełna odporność na 'wyspy'
- Małe wymagania pomiarowe komputerowe
### Wady
- Kształt 
- Zbyt rozbudowane drzewo traci na generalizacji
- Brak synergii zmiennych

Drzewo decyzyjne używa się też często do regresji

# Lasy decyzyjne - las losowy drzew decyzyjnych
- Tworzy się $k$ drzew decyzyjnych na lowowo dobranych zbiorach (zazwyczaj $\frac{2}{3}$)
- Każde drzewo wtedy są nauczone na swój sposób, z którego to tworzy się jeden klasyfikator będący efektywnie głosem większości, przez drzewa decyzyjne
- Węzły wtedy mogą być wielo-zmiennowe

Dobór liczby zmiennych w węzłach jest bardzo ważny
$$ M = \sqrt{N}\text{, gdzie N to liczba wszystkich zmiennych } $$ 

### Zalety
- Bardzo efektywny klasyfikator
- Selekcja ważności zmiennych $x_i$ przy podejmowaniu decyzji.
  - Generuje się las drzew decyzyjnych
  - Testuje się działanie danego lasu na danym zbiorze (błąd testowania w $E_n$)
  - Testuje się działanie danego lasu na zbiorze przy drobnej zmianie kolejnych zmiennych $x_i$
  - Selekcja jest podejmowana na wartościach $E_i$